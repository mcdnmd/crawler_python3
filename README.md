# crawler 
Version: 2.0

Автор: Полтораднев Кирилл
Дата: 25.12.2020

## Описание
Утилита краулер позволяет скачивать контент с выбранного сайта. Зная глубину и стартовую ссылку, робот начинает скачивать содержимое сайта в пределах глубины. Все ссылки сохраняются, соглсасно изначальной кодировке, в выбранной папке.


## Состав
* Файл запуска утилиты: `startup.py`
* Модули: `/modules`
* Тесты: `/tests`

### Управление
`python3 startup.py [-h] [-f FOLDER] [-j MAX_THREADS] [-d DEPTH] [-F FILTERS [FILTERS ...]] url`

Для работы утилита использует параметры:

* `-h`, `--help` отобразить сообщение help
* `-f FOLDER`, `--folder FOLDER` указать папку FOLDER для сохранения сайта (по умолчанию: в каталог `../startup.py`)
* `-j MAX_THREADS`, `--threads MAX_THREADS` указать максимальное кол-во MAX_THREADS возможных потоков (по умолчанию: 2 * кол-во ядер)
* `-d DEPTH` указать DEPTH глубину скачивания сайта (по умолчанию: 5)
* `-F FILTERS`, `--filter FILTERS` указать допустимые FILTERS сначало идет расширение, а затем макимальный размер (по умолчанию: css, js, xml)

### Пример использования фильтров
`python3 startup.py --filter .png 800 -f .jpeg https://somewebsite.url`

В данном примере мы `--filter .png 800` разрешаем скачивать файлы с расширением png объемом не более 800 байт и `-f .jpeg` разрешаем скачивать файлы jpeg любого размера.

## Подробности реализации
Модули, отвечающие за логику краулера расположены в пакете modules. 
* `modules.TerminalParser`- класс, реализующий argparser для обработки терминальной команды
* `modules.Url`- структура данных для представления URL адреса
* `modules.Crawler` - класс, формирующий цикл обработки данных
* `modules.PageParser`- класс, реализующий обрабоку страницы и верификацию ссылок
* `modules.LinkParser`- класс-потомок `html.parse.HTMLParser`, реализующий обработку данных из HTML файла
* `modules.StateHandler` - класс, реализующий запись и чтение из файла состояний `currentstate.json`
* `modules.HTTPClient` - класс, реализующий простой HTTP клиент
* `modules.FileSystemHandler` - класс, реализующий работу с файловой системой компьютера

### Дополнительно
В программе используется автодокументирование Doxygen
